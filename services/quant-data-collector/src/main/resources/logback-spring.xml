<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- 定义日志文件路径 -->
    <property name="LOG_PATH" value="./logs"/>
    <property name="APP_NAME" value="data-collector"/>
    <property name="LOG_TOPIC" value="log-quant-data-collector"/>
    <property name="KAFKA_BOOTSTRAP" value="${spring.kafka.bootstrap-servers:-192.168.254.2:9092,192.168.254.3:9092,192.168.254.4:9092}"/>
    <property name="HOST_NAME" value="${HOST_NAME:-unknown}"/>
    <property name="HOST_IP" value="${HOST_IP:-unknown}"/>
    <property name="HOST_PORT" value="${server.port:-8080}"/>
    <property name="ENV" value="${spring.profiles.active:-dev}"/>

    <!-- 控制台输出配置 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- 应用主日志 -->
    <appender name="APPLICATION_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/application.log</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/application.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>30</maxHistory>
            <totalSizeCap>3GB</totalSizeCap>
        </rollingPolicy>
    </appender>

    <!-- 错误日志 -->
    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/error.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/error.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
    </appender>

    <!-- 数据收集器业务日志 -->
    <appender name="DATA_COLLECTOR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/data-collector.log</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/data-collector.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
    </appender>

    <!-- 数据库操作日志 -->
    <appender name="DATABASE_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/database.log</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/database.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>15</maxHistory>
        </rollingPolicy>
    </appender>

    <!-- HTTP 请求日志 -->
    <appender name="HTTP_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/http.log</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/http.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>15</maxHistory>
        </rollingPolicy>
    </appender>

    <!-- 定时任务日志 -->
    <appender name="SCHEDULER_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/scheduler.log</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/scheduler.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>15</maxHistory>
        </rollingPolicy>
    </appender>

    <!-- Nacos日志文件 -->
    <appender name="FILE_NACOS" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/nacos.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_PATH}/nacos.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- Kafka 日志 Appender -->
    <appender name="KAFKA" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <!-- 使用LogstashEncoder将日志格式化为JSON格式 -->
        <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
            <providers class="net.logstash.logback.composite.loggingevent.LoggingEventJsonProviders">
                <!-- 自定义JSON格式模式 -->
                <pattern>
                    <pattern>
                        {
                        "env": "${ENV}",
                        "service": "${APP_NAME}",
                        "hostname": "${HOST_NAME}",
                        "ip": "${HOST_IP}",
                        "port": "${HOST_PORT}",
                        "level": "%level",
                        "thread": "%thread",
                        "logger": "%logger{36}",
                        "timestamp": "%date{yyyy-MM-dd'T'HH:mm:ss.SSSSSS'Z'}",
                        "message": "%msg",
                        "exception": "%exception"
                        }
                    </pattern>
                </pattern>
            </providers>
        </encoder>
        <!-- Kafka主题名称 -->
        <topic>${LOG_TOPIC}</topic>
        <!-- 键策略：使用服务名+IP作为键，便于分区和消费端识别 -->
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy"/>
        <!-- 传递策略：异步发送日志到Kafka -->
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
        
        <!-- Kafka生产者配置 -->
        <producerConfig>bootstrap.servers=${KAFKA_BOOTSTRAP}</producerConfig>
        <producerConfig>acks=1</producerConfig>
        <producerConfig>linger.ms=100</producerConfig>
        <producerConfig>batch.size=16384</producerConfig>
        <producerConfig>buffer.memory=33554432</producerConfig>
        <producerConfig>compression.type=snappy</producerConfig>
        <producerConfig>retries=3</producerConfig>
        <producerConfig>max.block.ms=5000</producerConfig>
    </appender>

    <!-- 异步日志配置 -->
    <appender name="ASYNC_APPLICATION" class="ch.qos.logback.classic.AsyncAppender">
        <discardingThreshold>0</discardingThreshold>
        <queueSize>1024</queueSize>
        <includeCallerData>false</includeCallerData>
        <appender-ref ref="APPLICATION_FILE"/>
    </appender>

    <appender name="ASYNC_ERROR" class="ch.qos.logback.classic.AsyncAppender">
        <discardingThreshold>0</discardingThreshold>
        <queueSize>256</queueSize>
        <includeCallerData>true</includeCallerData>
        <appender-ref ref="ERROR_FILE"/>
    </appender>

    <appender name="ASYNC_KAFKA" class="ch.qos.logback.classic.AsyncAppender">
        <queueSize>1024</queueSize>
        <discardingThreshold>0</discardingThreshold>
        <includeCallerData>false</includeCallerData>
        <appender-ref ref="KAFKA"/>
    </appender>

    <!-- 特定包的日志级别配置 -->
    <logger name="com.hao.datacollector" level="INFO" additivity="false">
        <appender-ref ref="DATA_COLLECTOR_FILE"/>
        <appender-ref ref="ASYNC_ERROR"/>
        <appender-ref ref="CONSOLE"/>
    </logger>

    <!-- 数据库相关日志 -->
    <logger name="com.zaxxer.hikari" level="INFO" additivity="false">
        <appender-ref ref="DATABASE_FILE"/>
        <appender-ref ref="CONSOLE"/>
    </logger>

    <logger name="org.mybatis" level="DEBUG" additivity="false">
        <appender-ref ref="DATABASE_FILE"/>
    </logger>

    <!-- HTTP 相关日志 -->
    <logger name="org.apache.coyote" level="INFO" additivity="false">
        <appender-ref ref="HTTP_FILE"/>
    </logger>

    <logger name="org.springframework.web" level="INFO" additivity="false">
        <appender-ref ref="HTTP_FILE"/>
    </logger>

    <!-- 定时任务日志 -->
    <logger name="com.xxl.job" level="INFO" additivity="false">
        <appender-ref ref="SCHEDULER_FILE"/>
        <appender-ref ref="CONSOLE"/>
    </logger>

    <!-- Spring Boot 启动相关日志级别调整 -->
    <logger name="org.springframework.boot" level="INFO"/>
    <logger name="org.springframework.web.servlet.mvc.method.annotation" level="WARN"/>
    <logger name="org.springframework.web.servlet.handler.HandlerMappingIntrospector" level="WARN"/>

    <!-- 环境配置 -->
    <springProfile name="dev,local">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_APPLICATION"/>
            <appender-ref ref="ASYNC_ERROR"/>
            <appender-ref ref="FILE_NACOS"/>
            <appender-ref ref="ASYNC_KAFKA"/>
        </root>
    </springProfile>

    <springProfile name="test">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_APPLICATION"/>
            <appender-ref ref="ASYNC_ERROR"/>
            <appender-ref ref="FILE_NACOS"/>
            <appender-ref ref="ASYNC_KAFKA"/>
        </root>
    </springProfile>

    <springProfile name="prod">
        <root level="WARN">
            <appender-ref ref="ASYNC_APPLICATION"/>
            <appender-ref ref="ASYNC_ERROR"/>
            <appender-ref ref="FILE_NACOS"/>
            <appender-ref ref="ASYNC_KAFKA"/>
        </root>
    </springProfile>
</configuration>